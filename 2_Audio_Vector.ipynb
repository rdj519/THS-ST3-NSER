{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1b7cd9",
   "metadata": {},
   "source": [
    "## Building Audio Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0fd98",
   "metadata": {},
   "source": [
    "We use the df file to split wav files into multiple frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c9408",
   "metadata": {},
   "source": [
    "Let's try one file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb64afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try for one file first\n",
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387a139",
   "metadata": {},
   "source": [
    "We see the audio signal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4cc51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.42572615,  0.48587543,  0.37312022, ..., -0.31514615,\n",
       "        -0.16263676,  0.        ], dtype=float32),\n",
       " 44100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'IEMOCAP_Extracted/IEMOCAP_full_release/Session1/dialog/wav/Ses01F_impro01.wav'\n",
    "\n",
    "y, sr = librosa.load(file_path, sr=44100)\n",
    "y, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29293f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "labels_df = pd.read_csv('df_iemocap.csv')\n",
    "iemocap_dir = 'IEMOCAP_Extracted/IEMOCAP_full_release/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17885fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [03:42<00:00, 10.69s/it]\n",
      "100%|██████████| 31/31 [03:43<00:00,  7.22s/it]\n",
      "100%|██████████| 32/32 [03:52<00:00,  7.28s/it]\n",
      "100%|██████████| 30/30 [04:23<00:00, 11.66s/it]\n",
      "100%|██████████| 31/31 [04:05<00:00, 10.36s/it]\n"
     ]
    }
   ],
   "source": [
    "sr = 44100\n",
    "\n",
    "audio_vectors = {}\n",
    "\n",
    "for sess in range(1,6):  # using one session due to memory constraint, can replace [5] with range(1, 6)\n",
    "    wav_file_path = '{}Session{}/dialog/wav/'.format(iemocap_dir, sess)\n",
    "    orig_wav_files = os.listdir(wav_file_path)\n",
    "    for orig_wav_file in tqdm(orig_wav_files):\n",
    "        if orig_wav_file == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        elif orig_wav_file[7] == 's':\n",
    "            continue\n",
    "        try:\n",
    "            orig_wav_vector, _sr = librosa.load(wav_file_path + orig_wav_file, sr=sr)\n",
    "            orig_wav_file, file_format = orig_wav_file.split('.')\n",
    "            for index, row in labels_df[labels_df['wav_file'].str.contains(orig_wav_file)].iterrows():\n",
    "                start_time, end_time, truncated_wav_file_name, emotion, val, act, dom = row['start_time'], row['end_time'], row['wav_file'], row['emotion'], row['val'], row['act'], row['dom']\n",
    "                start_frame = math.floor(start_time * sr)\n",
    "                end_frame = math.floor(end_time * sr)\n",
    "                truncated_wav_vector = orig_wav_vector[start_frame:end_frame + 1]\n",
    "                audio_vectors[truncated_wav_file_name] = truncated_wav_vector\n",
    "        except:\n",
    "            print('An exception occured for {}'.format(orig_wav_file))\n",
    "    with open('IEMOCAP_Data/PreProcessed/AudioVectors/audio_vectors_{}.pkl'.format(sess), 'wb') as f:\n",
    "        pickle.dump(audio_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da32b63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
